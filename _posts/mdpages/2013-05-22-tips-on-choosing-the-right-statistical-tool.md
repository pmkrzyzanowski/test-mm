---
title: "Tips on Choosing the Right Statistical Tool"
---

[Here's a poster](http://figshare.com/articles/Navigating_the_statistical_maze_ASM_poster/704838) that provides a very quick overview of a resource that helps choose statistical tests for biological data, or most other data for that matter.
The basic BioStat Decision Tool, developed by two biologists at the University of Auckland, is available as a [free web tool](http://flexiblelearning.auckland.ac.nz/biostat-tree/) and also as a paid app for portable devices like iPads, which is an interesting decision on part of the creators. It basically runs through a decision tree to help people choose which statistical test to use for their data and seems like a useful site to bookmark.

What caught my attention was the presentation of how bad the issue of statistical fumbling in literature was (thus making the BioStat Tool necessary):

> Common errors found in half of published biomedical papers (1979–2003)
<ul><li>Failure to adjust or account for multiple comparisons</li><li>Reporting that a result is “significant” without conducting a statistical test</li><li>Use of statistical tests that assume a normal distribution on data that is skewed</li><li>Unlabelled or inappropriate error bars/measures of variability</li><li>Failure to describe the tests performed</li></ul>

Really? Granted, these statements are derived from [a review of articles](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC308915/) in *Infection in Immunity*, but I didn't think the error rate was that high. Maybe the rate is lower for other journals, or more recent articles, but 50% is pretty shameful.
Finally, there's a call to action in the poster, too:

> If we are to improve the quality of published biomedical papers, it is clear that we need a paradigm shift in the way biologists approach data presentation, statistics and data analysis.

I don't know about *paradigm shift*, but easy to use tools that guide people through the many options offered by the stats field are a step in the right direction. Some education and pushback from referees and editors would be even better.

